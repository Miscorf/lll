{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 基本库\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 加载音频处理库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 其他库\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 特征提取以及数据集的建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aloe': 0, 'burger': 1, 'cabbage': 2, 'candied_fruits': 3, 'carrots': 4, 'chips': 5, 'chocolate': 6, 'drinks': 7, 'fries': 8, 'grapes': 9, 'gummies': 10, 'ice-cream': 11, 'jelly': 12, 'noodles': 13, 'pickles': 14, 'pizza': 15, 'ribs': 16, 'salmon': 17, 'soup': 18, 'wings': 19}\n",
      "{0: 'aloe', 1: 'burger', 2: 'cabbage', 3: 'candied_fruits', 4: 'carrots', 5: 'chips', 6: 'chocolate', 7: 'drinks', 8: 'fries', 9: 'grapes', 10: 'gummies', 11: 'ice-cream', 12: 'jelly', 13: 'noodles', 14: 'pickles', 15: 'pizza', 16: 'ribs', 17: 'salmon', 18: 'soup', 19: 'wings'}\n"
     ]
    }
   ],
   "source": [
    "feature = []\n",
    "label = []\n",
    "# 建立类别标签，不同类别对应不同的数字。\n",
    "label_dict = {'aloe': 0, 'burger': 1, 'cabbage': 2,'candied_fruits':3, 'carrots': 4, 'chips':5,\n",
    "                  'chocolate': 6, 'drinks': 7, 'fries': 8, 'grapes': 9, 'gummies': 10, 'ice-cream':11,\n",
    "                  'jelly': 12, 'noodles': 13, 'pickles': 14, 'pizza': 15, 'ribs': 16, 'salmon':17,\n",
    "                  'soup': 18, 'wings': 19}\n",
    "label_dict_inv = {v:k for k,v in label_dict.items()}\n",
    "print(label_dict)\n",
    "print(label_dict_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def extract_features(parent_dir, sub_dirs, max_file=10, file_ext=\"*.wav\"):\n",
    "    c = 0\n",
    "    label, feature = [], []\n",
    "    for sub_dir in sub_dirs:\n",
    "        for fn in tqdm(glob.glob(os.path.join(parent_dir, sub_dir, file_ext))[:max_file]): # 遍历数据集的所有文件\n",
    "            \n",
    "            # segment_log_specgrams, segment_labels = [], []\n",
    "            #sound_clip,sr = librosa.load(fn)\n",
    "            # print(fn)\n",
    "            label_name = fn.split('/')[-2]\n",
    "            # print(label_name)\n",
    "            \n",
    "            label.extend([label_dict[label_name]])\n",
    "            X, sample_rate = librosa.load(fn,res_type='kaiser_fast')\n",
    "            mels = np.mean(librosa.feature.melspectrogram(y=X,sr=sample_rate).T,axis=0) # 计算梅尔频谱(mel spectrogram),并把它作为特征\n",
    "            feature.extend([mels])\n",
    "    \n",
    "    return [feature, label]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:05<00:00,  8.74it/s]\n",
      "100%|██████████| 64/64 [00:07<00:00,  8.55it/s]\n",
      "100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n",
      "100%|██████████| 74/74 [00:12<00:00,  6.02it/s]\n",
      "100%|██████████| 49/49 [00:07<00:00,  6.55it/s]\n",
      "100%|██████████| 57/57 [00:08<00:00,  6.47it/s]\n",
      "100%|██████████| 27/27 [00:03<00:00,  6.83it/s]\n",
      "100%|██████████| 27/27 [00:03<00:00,  6.88it/s]\n",
      "100%|██████████| 57/57 [00:08<00:00,  7.00it/s]\n",
      "100%|██████████| 61/61 [00:09<00:00,  6.69it/s]\n",
      "100%|██████████| 65/65 [00:10<00:00,  6.42it/s]\n",
      "100%|██████████| 69/69 [00:10<00:00,  6.37it/s]\n",
      "100%|██████████| 43/43 [00:06<00:00,  6.73it/s]\n",
      "100%|██████████| 33/33 [00:04<00:00,  7.03it/s]\n",
      "100%|██████████| 75/75 [00:11<00:00,  6.41it/s]\n",
      "100%|██████████| 55/55 [00:09<00:00,  6.04it/s]\n",
      "100%|██████████| 47/47 [00:07<00:00,  6.25it/s]\n",
      "100%|██████████| 37/37 [00:06<00:00,  6.09it/s]\n",
      "100%|██████████| 32/32 [00:03<00:00,  8.39it/s]\n",
      "100%|██████████| 35/35 [00:05<00:00,  6.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# 自己更改目录  \n",
    "parent_dir = '../data/train_sample/'\n",
    "save_dir = \"../data\"\n",
    "folds = sub_dirs = np.array(['aloe','burger','cabbage','candied_fruits',\n",
    "                             'carrots','chips','chocolate','drinks','fries',\n",
    "                            'grapes','gummies','ice-cream','jelly','noodles','pickles',\n",
    "                            'pizza','ribs','salmon','soup','wings'])\n",
    "\n",
    "# 获取特征feature以及类别的label\n",
    "\n",
    "temp = extract_features(parent_dir,sub_dirs,max_file=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X的特征尺寸是 (1000, 128)\n",
      "Y的特征尺寸是 (1000,)\n"
     ]
    }
   ],
   "source": [
    "temp = np.array(temp)\n",
    "data = temp.transpose()\n",
    "# 转置\n",
    "# 获取特征\n",
    "X = np.vstack(data[:, 0])\n",
    "\n",
    "# 获取标签\n",
    "Y = np.array(data[:, 1],dtype= int)\n",
    "print('X的特征尺寸是',X.shape)\n",
    "print('Y的特征尺寸是',Y.shape)\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "# Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 128)\n",
      "(1000, 8, 1, 16, 1)\n",
      "(1000, 1)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# 最终数据\n",
    "print(X.shape)\n",
    "# X = X.reshape(-1, 1, 16, 8, 1)\n",
    "X = X.reshape(-1, 8, 1, 16, 1)\n",
    "Y = Y.reshape(-1,1)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(Y.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "# from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "# from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 8, 1, 16, 1])\n",
      "tensor([13])\n"
     ]
    }
   ],
   "source": [
    "b = torch.from_numpy(X)\n",
    "#c = Y\n",
    "c = torch.from_numpy(Y)\n",
    "print(b.size())\n",
    "X_train, X_test, y_train, y_test = train_test_split(b, c, test_size=0.1, random_state=42)\n",
    "print(y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于分布式光纤传感器的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,8,3,padding=2)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(8,16,3,padding=2)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        self.fla = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(640,1024)\n",
    "        self.fc2 = nn.Linear(1024,20)\n",
    "        # self.conv1 = nn.Conv2d(1,6,5,padding=2)\n",
    "        # self.pool = nn.MaxPool2d(2,2)\n",
    "        # self.conv2 = nn.Conv2d(6,16,3,padding=2)\n",
    "        # self.avgpool = nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        # self.fla = nn.Flatten()\n",
    "        # self.fc1 = nn.Linear(5*48,1024)\n",
    "        # self.fc2 = nn.Linear(1024,20)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.tanh(x)\n",
    "        x = self.pool(x)\n",
    "        # tanh 较好\n",
    "        x = self.conv2(x)\n",
    "        x = F.tanh(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # x = x.view(-1, (28*28)//(4*4)*8)\n",
    "        x = x.view(-1,640)\n",
    "        x = self.fc1(x)\n",
    "        x = F.tanh(x)\n",
    "\n",
    "        x = F.dropout(x, p=0.3,training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def feature_maps(self, x):\n",
    "        map1 = self.conv1(x)\n",
    "        map1 = F.tanh(map1)\n",
    "        map2 = self.pool(map1)\n",
    "        map2 = self.conv2(map2)\n",
    "        # map2 = F.relu(map2)\n",
    "        map2 = F.tanh(map2)\n",
    "        return (map1, map2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4402)\n",
      "tensor([[1., 2., 3., 4.]])\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "predicted = torch.tensor([[1,2,3,4]]).float()\n",
    "target = torch.tensor([1]).long()\n",
    "lossfxn = nn.CrossEntropyLoss()\n",
    "loss = lossfxn(predicted, target)\n",
    "print(loss) # outputs tensor(2.4402)\n",
    "print(predicted)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 8, 1, 16, 1])\n",
      "0 tensor(2.7175, grad_fn=<NllLossBackward>)\n",
      "1 tensor(2.4992, grad_fn=<NllLossBackward>)\n",
      "2 tensor(2.2202, grad_fn=<NllLossBackward>)\n",
      "3 tensor(1.9326, grad_fn=<NllLossBackward>)\n",
      "4 tensor(1.2513, grad_fn=<NllLossBackward>)\n",
      "5 tensor(0.8225, grad_fn=<NllLossBackward>)\n",
      "6 tensor(0.5927, grad_fn=<NllLossBackward>)\n",
      "7 tensor(0.4006, grad_fn=<NllLossBackward>)\n",
      "8 tensor(0.2770, grad_fn=<NllLossBackward>)\n",
      "9 tensor(0.5465, grad_fn=<NllLossBackward>)\n",
      "10 tensor(0.2614, grad_fn=<NllLossBackward>)\n",
      "11 tensor(0.3155, grad_fn=<NllLossBackward>)\n",
      "12 tensor(0.4322, grad_fn=<NllLossBackward>)\n",
      "13 tensor(0.3573, grad_fn=<NllLossBackward>)\n",
      "14 tensor(0.1938, grad_fn=<NllLossBackward>)\n",
      "15 tensor(0.2373, grad_fn=<NllLossBackward>)\n",
      "16 tensor(0.1336, grad_fn=<NllLossBackward>)\n",
      "17 tensor(0.0477, grad_fn=<NllLossBackward>)\n",
      "18 tensor(0.1081, grad_fn=<NllLossBackward>)\n",
      "19 tensor(0.0505, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "net = model()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(net.parameters(),lr = 0.001,momentum=0.9)\n",
    "print(b.shape)\n",
    "for epoch in range(20):\n",
    "    for i,da in enumerate(X_train):\n",
    "        x = da\n",
    "        # print(x)\n",
    "        y = y_train[i]\n",
    "        # y = torch.tensor([1]).long()\n",
    "        # y = y.unsqueeze(-2)\n",
    "        # print(y)\n",
    "        net.train()#打开dropout\n",
    "        pred=net(x)\n",
    "        # print(pred)\n",
    "        loss=loss_fn(pred,y)\n",
    "        # print(i,loss)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(epoch,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(a,b):\n",
    "    acc  = 0\n",
    "    for i,da in enumerate(a):\n",
    "        x = da\n",
    "        # print(x)\n",
    "        y = b[i]\n",
    "        pred=net(x)\n",
    "        pred = pred.squeeze()\n",
    "        # print(pred)\n",
    "        m = max(pred)\n",
    "        pre_list = pred.tolist()\n",
    "        ind = pre_list.index(m)\n",
    "        y_list = y.tolist()\n",
    "        y_max = max(y_list)\n",
    "        y_ind = y_list.index(y_max)\n",
    "\n",
    "        if ind == y_ind:\n",
    "            acc += 1\n",
    "        # print(ind, y_ind)\n",
    "    print(acc/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09\n",
      "0.06333333333333334\n"
     ]
    }
   ],
   "source": [
    "accuracy(X_test,y_test)\n",
    "accuracy(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('foodVoice')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "tianchi_metadata": {
   "competitions": [],
   "datasets": [
    {
     "id": "96728",
     "title": "获取数据集标题失败"
    }
   ],
   "description": "",
   "notebookId": "185525",
   "source": "dsw"
  },
  "vscode": {
   "interpreter": {
    "hash": "a35a5ff58b060d3e8e40d5a274dfca8c253152deb5bb2796b761379e6aa5cd6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
